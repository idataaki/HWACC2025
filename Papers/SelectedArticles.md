# Selected Articles for 2024

This document contains a list of selected research articles from top conferences in computer architecture, focusing on Processing-in-Memory (PIM), Large Language Model (LLM) acceleration, memory management, and efficient matrix operations.

## HPCA (IEEE International Symposium on High-Performance Computer Architecture)
- **PIM-MMU**: A Memory Management Unit for Accelerating Data Transfers in Commercial PIM Systems  
- **MIMDRAM**: An End-to-End Processing-Using-DRAM System for High-Throughput, Energy-Efficient, and Programmer-Transparent Multiple-Instruction Multiple-Data Computing  
- **StreamPIM**: Streaming Matrix Computation in Racetrack Memory  
- **Smart Infinity**: Fast Large Language Model Training Using Near Storage Processing on a Real System  
- **Rapper**: A Parameter-Aware Repair-in-Memory Accelerator for Blockchain Storage Platform  

## ISCA (International Symposium on Computer Architecture)
- **MECLA**: Memory-Compute-Efficient LLM Accelerator with Scaling Sub-Matrix Partition  
- **FEATHER**: A Reconfigurable Accelerator with Data Reordering Support for Low-Cost On-Chip Dataflow Switching  
- **BBS**: Bi-Directional Bit-Level Sparsity for Deep Learning Acceleration  
- **Cambricon-D**: Full-Network Differential Acceleration for Diffusion Models  

## MICRO (IEEE/ACM International Symposium on Microarchitecture)
- **Stream-Based Data Placement**: Near-Data Processing with Extended Memory  
- **Cambricon-C**: Efficient 4-bit Matrix Unit via Primitivization  
- **PyPIM**: Integrating Digital Processing-in-Memory from Microarchitectural Design to Python Tensors  
- **FuseMax**: Leveraging Extended Einsums to Optimize Attention Accelerator Design  
- **Splitwise**: Efficient Generative LLM Inference Using Phase Splitting  
- **Stellar**: An Automated Design Framework for Dense and Sparse Spatial Accelerators  

---

This list covers key innovations in high-performance computing, including advancements in memory management, processing-in-memory architectures, and efficient deep learning accelerators.
